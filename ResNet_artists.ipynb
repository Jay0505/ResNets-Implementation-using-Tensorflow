{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def read_train_images(file_path):\n",
    "\n",
    "    inner_dirs_path = [path for path in glob.glob(file_path + '*') if 'train' in path]\n",
    "    images_arr = {}\n",
    "    for dir_path in inner_dirs_path:\n",
    "        images_names = os.listdir(dir_path)\n",
    "        images_arr = read_image_(dir_path, images_names, images_arr)\n",
    "        \n",
    "    return pd.DataFrame(images_arr.items(), columns = ['image_name', 'pixel_data'])\n",
    "    \n",
    "\n",
    "\n",
    "##########################################################    \n",
    "\n",
    "def read_image_(path, image_names, images_arr):\n",
    "    \n",
    "    try:\n",
    "        for image_name in image_names:\n",
    "            \n",
    "            if image_name.split(\".\")[-1].lower() in {\"jpeg\", \"jpg\", \"png\"}:\n",
    "#                 print(image_name, count)\n",
    "                image     = cv2.resize(cv2.imread(path + \"/\" + image_name), (224, 224))\n",
    "                image     = image / 255\n",
    "                images_arr[str(image_name)] = image\n",
    "\n",
    "                    \n",
    "        return images_arr\n",
    "    \n",
    "   \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def read_artists_names(path):\n",
    "    image_name_dict = {}\n",
    "    with open(path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        column_headers = next(reader)\n",
    "        artist_ = column_headers.index('artist')\n",
    "        file_name = column_headers.index('new_filename')\n",
    "        in_train = column_headers.index('in_train')\n",
    "\n",
    "        for row in reader:\n",
    "            if bool(row[in_train]):\n",
    "                image_name_dict[row[file_name]] = row[artist_]\n",
    "                \n",
    "        \n",
    "    return pd.DataFrame(image_name_dict .items(), columns = ['image_name', 'artist_name'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def merge_image_data_artists_data_dfs(image_df, artist_df):\n",
    "    images_artist_df = pd.merge(image_df, artist_df, on = 'image_name')\n",
    "    #images_artist_df.drop('image_name', axis = 1, inplace = True)\n",
    "    return images_artist_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def add_unique_artist_names_as_columns_to_df(image_artist_df):\n",
    "    '''\n",
    "    This function converts all the unique artist names in artist_name column to separate column names in \n",
    "    the new dataframe and add a value of '1' for each image painted by the particular artist\n",
    "    '''\n",
    "    dummy_column    = np.ones(np.shape(image_artist_df)[0])\n",
    "    artist_img_name_df = image_artist_df.filter(['image_name', 'pixel_data'], axis = 1)\n",
    "    image_artist_df.drop('pixel_data', axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    image_artist_df['dummy'] = dummy_column\n",
    "    image_artist_mod_df = image_artist_df.pivot_table(values = 'dummy', \n",
    "                                                      index = ['image_name'], \n",
    "                                                      columns = 'artist_name')\n",
    "    image_artist_mod_df.columns.name = None\n",
    "    image_artist_mod_df.reset_index(inplace = True)\n",
    "    image_artist_mod_df.fillna(0)\n",
    "    \n",
    "    return pd.merge(artist_img_name_df, image_artist_mod_df, on = 'image_name')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def get_input_and_label_data_dfs(image_artist_mod_df):\n",
    "    input_data_ = []\n",
    "    input_data_df = image_artist_mod_df['pixel_data'].values\n",
    "    for value in input_data_df:\n",
    "        input_data_.append(value)\n",
    "    image_artist_mod_df.drop('pixel_data', axis = 1, inplace = True)\n",
    "    \n",
    "    image_artist_mod_df.drop('image_name', axis = 1, inplace = True)\n",
    "    \n",
    "    return np.array(input_data_), image_artist_mod_df\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def get_train_and_label_data(train_data, test_data):\n",
    "\n",
    "    no_of_rows = np.shape(train_data)[0]\n",
    "    no_of_train_samples = int(math.modf(no_of_rows * 0.8)[1])\n",
    "    train_X = train_data[0 : no_of_train_samples]\n",
    "    train_Y = test_data[0 : no_of_train_samples]\n",
    "    \n",
    "    test_X = train_data[no_of_train_samples : ]\n",
    "    test_Y = test_data[no_of_train_samples : ]\n",
    "    \n",
    "    return [[train_X, train_Y], [test_X, test_Y]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = read_train_images('/Users/vijay/Downloads/Datasets/Painter-by-numbers/')\n",
    "print('-----------')\n",
    "artists_df = read_artists_names('/Users/vijay/Downloads/Datasets/Painter-by-numbers/all_data_info.csv')\n",
    "print('-----------')\n",
    "images_artist_df = merge_image_data_artists_data_dfs(images_df, artists_df)\n",
    "print('-----------')\n",
    "image_artist_mod_df = add_unique_artist_names_as_columns_to_df(images_artist_df)\n",
    "print('-----------')\n",
    "X, Y = get_input_and_label_data_dfs(image_artist_mod_df)\n",
    "\n",
    "del(images_df)\n",
    "del(artists_df)\n",
    "del(images_artist_df)\n",
    "\n",
    "\n",
    "train_test_data = get_train_and_label_data(X, Y.values)\n",
    "train_X, train_Y = train_test_data[0]\n",
    "test_X, test_Y   = train_test_data[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(train_X))\n",
    "print(np.shape(train_Y))\n",
    "print(np.shape(test_X))\n",
    "print(np.shape(test_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "batch_size      = 400\n",
    "classes         = tf.constant(10, tf.int8, name = \"classes\")\n",
    "no_of_labels    = np.shape(train_Y)[1]\n",
    "\n",
    "\n",
    "filter_channels = tf.Variable([64, 128, 256],name ='filter_channels')\n",
    "no_of_resd_blocks = tf.Variable([3, 6, 4], name = 'no_of_resd_blocks')\n",
    "\n",
    "\n",
    "\n",
    "flt_shape = tf.Variable(3)\n",
    "dim_change_flt_shape = tf.Variable(1)\n",
    "dim_change_stride = tf.Variable(2)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = [None, 224 * 224 * 3], name = \"x\")\n",
    "x_rs = tf.reshape(x, shape = [-1, 224, 224, 3])\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape = [None, no_of_labels], name = \"y\")\n",
    "y_rs = tf.reshape(y, [-1, no_of_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_scale_and_gamma_variables(shape):\n",
    "    scale = tf.Variable(tf.ones(shape))\n",
    "    offset = tf.Variable(tf.zeros(shape))\n",
    "    \n",
    "    return scale, offset\n",
    "\n",
    "\n",
    "def batch_normalize(data, shape):\n",
    "    \n",
    "    scale, offset = get_scale_and_gamma_variables(shape)\n",
    "    mean, var     = tf.nn.moments(data, axes = [0, 1, 2])\n",
    "    \n",
    "    data_norm     = tf.nn.batch_normalization(data, mean, var, scale, offset, 0.05, name = \"BN\")\n",
    "    \n",
    "    return data_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_flt_channels_and_resd_blocks():\n",
    "    '''No_of_filters and no_of_blocks in each residual layer'''\n",
    "    return [64, 128, 256, 512], [6, 8, 12, 6]\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def get_conv_and_pool_params_at_stage_1():\n",
    "    \n",
    "    conv_flt_shape = ([7, 7, 3, 64]) # [flt_shape, flt_shape, channels, number_of_filters]\n",
    "    conv_stride    = ([1, 2, 2, 1])\n",
    "    pool_shape     = ([1, 2, 2, 1])\n",
    "    pool_stride    = ([1, 2, 2, 1])\n",
    "    \n",
    "    return conv_flt_shape, conv_stride, pool_shape, pool_stride\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def get_weight(w_name, shape, dtype):\n",
    "    \n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev = 0.2, seed = 23, dtype = tf.float32), name = w_name)\n",
    "  \n",
    "    \n",
    "    \n",
    "\n",
    "##########################################################\n",
    "\n",
    "def get_total_no_of_neurons(shape_of_conv_out):\n",
    "    neurons = 1\n",
    "    for num in shape_of_conv_out:\n",
    "        if num is not None:\n",
    "            neurons = neurons * num\n",
    "    return neurons\n",
    "    \n",
    "\n",
    "##########################################################\n",
    "\n",
    "def conv_bn_relu_stage_1(data, conv_flt_shape, stride, pool_size, pool_stride):\n",
    "    \n",
    "    conv_flt  = get_weight(\"weight1\", conv_flt_shape, tf.float32)\n",
    "    \n",
    "    data      = tf.nn.conv2d(data, conv_flt, strides = stride, padding = \"SAME\")\n",
    "    data_norm = batch_normalize(data, conv_flt_shape[-1])\n",
    "    data_relu = tf.nn.relu(data_norm)\n",
    "    data_pool = tf.nn.max_pool(data, ksize = pool_size, strides = pool_stride, padding = 'SAME')\n",
    "    \n",
    "    return data_pool\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "'''\n",
    "This function is equla to one residual block in each residual layer\n",
    "'''\n",
    "def conv_bn_relu_resd_stage(data, conv_flt_shape, stride_1, stride_2, stride_3, padding_1, padding_2, padding_3,\n",
    "                                            dim_change, in_channels, num_channels, block_no):\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(\"conv_1_resd\"):\n",
    "        \n",
    "        tf.cast(conv_flt_shape, tf.int32)\n",
    "        conv_wt_1 = get_weight((\"conv_wt_1_\" + str(block_no) + \"_\"+ str(num_channels)), conv_flt_shape, tf.float32)\n",
    "        conv_1    = tf.nn.conv2d(data, conv_wt_1, strides = [1, stride_1, stride_1, 1], padding = padding_1)\n",
    "        bn_1      = batch_normalize(conv_1, conv_1.get_shape().as_list()[-1]) \n",
    "        relu_1    = tf.nn.relu(bn_1)\n",
    "    \n",
    "    with tf.variable_scope('conv_2_resd'):\n",
    "\n",
    "        conv_flt_shape_2 = [3, 3, relu_1.get_shape().as_list()[-1], num_channels]\n",
    "        conv_wt_2 = get_weight((\"conv_wt_2_\" + str(block_no) + \"_\"+ str(num_channels)), conv_flt_shape_2, tf.float32)\n",
    "        conv_2    = tf.nn.conv2d(relu_1, conv_wt_2, strides = [1, stride_2, stride_2, 1], padding = padding_2)\n",
    "        bn_2      = batch_normalize(conv_2, conv_2.get_shape().as_list()[-1])\n",
    "        \n",
    "    '''for shortcut connection between different blocks'''\n",
    "    if dim_change:\n",
    "        #shp       = dim_change_flt_shape\n",
    "        #stride    = dim_change_stride\n",
    "        shp = 1\n",
    "        \n",
    "        conv_wt   = get_weight((\"shrt_conv_wt_\" + str(block_no) + \"_\"+ str(num_channels)), [shp, shp, in_channels, num_channels], tf.float32)\n",
    "        shrtct_in = tf.nn.conv2d(data, conv_wt, strides = [1, stride_3, stride_3, 1], padding = padding_3) \n",
    "\n",
    "        return tf.nn.relu(bn_2 + shrtct_in)\n",
    "    \n",
    "    else:\n",
    "        return tf.nn.relu(bn_2 + data)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "##########################################################\n",
    "\n",
    "def residual_block(r_data, num_channels, use_1_by_1_conv = False, first_block = False, block_no = 0):\n",
    "    \n",
    "    '''if first_block, then we have to increase the volumne\n",
    "       if use_1_by_1_conv then we have to change the dimensions of the shortcut input to the addition after last block'''\n",
    "    \n",
    "    stride_1 = 1\n",
    "    stride_2 = 1\n",
    "    stride_3 = 1\n",
    "    padding_1 = 'SAME'\n",
    "    padding_2 = 'SAME'\n",
    "    padding_3 = 'SAME'\n",
    "    \n",
    "    dim_change = False\n",
    "    in_channels = r_data.get_shape().as_list()[-1]\n",
    "    conv_flt_shape = [3, 3, in_channels, num_channels]\n",
    "    \n",
    "    if use_1_by_1_conv:\n",
    "        stride_3 = 2\n",
    "        padding_3 = 'VALID'\n",
    "        dim_change = True\n",
    "        conv_flt_shape = [3, 3, num_channels, num_channels]\n",
    "    if first_block:\n",
    "        stride_1 = 2  \n",
    "        dim_change = True\n",
    "        conv_flt_shape = [3, 3,  in_channels, num_channels]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    output = conv_bn_relu_resd_stage(r_data, conv_flt_shape, stride_1, stride_2, stride_3, padding_1, padding_2, \n",
    "                                          padding_3, dim_change, in_channels, num_channels, block_no)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "\n",
    "def fully_connected_layer(data, num_of_labels):\n",
    "    \n",
    "    data_norm = batch_normalize(data, data.get_shape().as_list()[-1])\n",
    "    \n",
    "    \n",
    "    data_shape = data_norm.get_shape().as_list()\n",
    "    total_no_of_neurons = get_total_no_of_neurons(data_shape)\n",
    "    \n",
    "    \n",
    "    fc_wt_1 = get_weight('fc_wt_1', tf.cast([total_no_of_neurons, no_of_labels], tf.int32), tf.float32)\n",
    "    fc_b_1  = get_weight('fc_b_1', [no_of_labels], tf.float32)\n",
    "    data_flatten = tf.reshape(data_norm, shape = [-1, total_no_of_neurons])\n",
    "    \n",
    "    fc_layer_out    = tf.add(tf.matmul(data_flatten, fc_wt_1), fc_b_1)\n",
    "    \n",
    "    return fc_layer_out\n",
    " \n",
    "    \n",
    "    \n",
    "##########################################################\n",
    "\n",
    "def perfom_average_pooling(data):\n",
    "    return tf.nn.avg_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "            \n",
    "    \n",
    "    \n",
    "##########################################################\n",
    "\n",
    "def form_residual_blocks_and_fc_ouput():\n",
    "    \n",
    "    result_at_every_stage = []    \n",
    "    use_1_by_1_conv = False\n",
    "    first_block     = False\n",
    "    c_flt_shape, c_stride, pool_shape, pool_stride = get_conv_and_pool_params_at_stage_1()\n",
    "    x_1 = conv_bn_relu_stage_1(x_rs, c_flt_shape, c_stride, pool_shape, pool_stride)\n",
    "    result_at_every_stage.append(x_1)\n",
    "    \n",
    "    '''\n",
    "    filter_channels(64, 128, 256, 512) correspond to no_of_filters in various residual blocks\n",
    "    no_of_blocks correspond to number of cn-bn-relu-cn-bn-relu blocks in each residual block\n",
    "    '''    \n",
    "    \n",
    "    flt_channels, resd_blocks = get_flt_channels_and_resd_blocks()\n",
    "    \n",
    "    for flt_row in range(0, np.shape(flt_channels)[0]):\n",
    "        for resd_row in range(0, np.shape(resd_blocks)[0]):\n",
    "            if flt_row == resd_row:\n",
    "                num_channels = flt_channels[flt_row]\n",
    "                num     = resd_blocks[resd_row]\n",
    "                \n",
    "                for block_no in range(0, num):\n",
    "                    \n",
    "                    with tf.variable_scope(\"block_\" + str(block_no), reuse = True): \n",
    "                        if block_no == 0:\n",
    "                            if num_channels != 16:\n",
    "                                use_1_by_1_conv = True\n",
    "                                first_block     = True\n",
    "                            \n",
    "                            result_at_every_stage.append(residual_block(result_at_every_stage[-1], num_channels,\n",
    "                                                                        use_1_by_1_conv, first_block, block_no))\n",
    "                            use_1_by_1_conv = False\n",
    "                            first_block = False\n",
    "\n",
    "                        else:\n",
    "                            result_at_every_stage.append(residual_block(result_at_every_stage[-1], num_channels, False, False, \n",
    "                                                                                   block_no))\n",
    "\n",
    "                \n",
    "    avg_pool_res = perfom_average_pooling(result_at_every_stage[-1]) \n",
    "    \n",
    "    fc_output_layer = fully_connected_layer(avg_pool_res, classes)\n",
    "    \n",
    "    return fc_output_layer\n",
    "                \n",
    "                \n",
    "                \n",
    "########################################################## \n",
    "    \n",
    "    \n",
    "def ResNet_model():\n",
    "    \n",
    "    resnet_model        = form_residual_blocks_and_fc_ouput()\n",
    "    \n",
    "    cost                = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_rs, logits = resnet_model))\n",
    "    train_optim         = tf.train.AdamOptimizer(learning_rate =0.001).minimize(cost)\n",
    "    correctly_predicted = tf.equal(tf.argmax(resnet_model, 1), tf.argmax(y_rs, 1))\n",
    "    accuracy            = tf.reduce_mean(tf.cast(correctly_predicted, tf.float32))\n",
    "    \n",
    "    return resnet_model, train_optim, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ResNet_model():\n",
    "    with tf.Session() as session:\n",
    "        count = 0\n",
    "        model, optimizer, accuracy = ResNet_model()\n",
    "        \n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver(tf.trainable_variables())\n",
    "\n",
    "        for epoch in range(0, 1):\n",
    "            for i in range(0, len(train_X), batch_size):\n",
    "                \n",
    "                train_x = train_X[i : i + batch_size, :]\n",
    "                train_y = train_Y[i : i + batch_size, :]\n",
    "                _, accuracy_val = session.run([optimizer, accuracy], feed_dict = {x_rs : train_x, \n",
    "                                                                                  y_rs : train_y })\n",
    "\n",
    "                print(accuracy_val)\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                print(epoch, accuracy_val)\n",
    "\n",
    "    \n",
    "        save_path = saver.save(session, \"./resnet_artist_model\")\n",
    "        \n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_fc = run_ResNet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    meta_graph = tf.train.import_meta_graph('/resnet_artist_model.meta')\n",
    "    meta_graph.restore(session, tf.train.latest_checkpoint('./'))\n",
    "    \n",
    "    prediction = session.run(resnet_fc, feed_dict = {x_rs : test_x_reshaped})\n",
    "    print((session.run(tf.nn.softmax(prediction))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
