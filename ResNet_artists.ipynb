{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "batch_size      = 50 \n",
    "classes         = tf.constant(10, tf.int8, name = \"classes\")\n",
    "no_of_labels = 10\n",
    "\n",
    "\n",
    "filter_channels = tf.Variable([64, 128, 256],name ='filter_channels')\n",
    "no_of_resd_blocks = tf.Variable([3, 6, 4], name = 'no_of_resd_blocks')\n",
    "\n",
    "\n",
    "\n",
    "flt_shape = tf.Variable(3)\n",
    "dim_change_flt_shape = tf.Variable(1)\n",
    "dim_change_stride = tf.Variable(2)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = [None, 28 * 28], name = \"x\")\n",
    "x_rs = tf.reshape(x, shape = [-1, 28, 28, 1])\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape = [None, 10], name = \"y\")\n",
    "y_rs = tf.reshape(y, [-1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_scale_and_gamma_variables(shape):\n",
    "    scale = tf.Variable(tf.ones(shape))\n",
    "    offset = tf.Variable(tf.zeros(shape))\n",
    "    \n",
    "    return scale, offset\n",
    "\n",
    "\n",
    "def batch_normalize(data, shape):\n",
    "    \n",
    "    scale, offset = get_scale_and_gamma_variables(shape)\n",
    "    mean, var     = tf.nn.moments(data, axes = [0, 1, 2])\n",
    "    \n",
    "    data_norm     = tf.nn.batch_normalization(data, mean, var, scale, offset, 0.05, name = \"BN\")\n",
    "    \n",
    "    return data_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_flt_channels_and_resd_blocks():\n",
    "    \n",
    "\n",
    "    return [16, 32, 64], [3, 6, 4]\n",
    "\n",
    "\n",
    "#---------------------------#---------------------------------------#\n",
    "\n",
    "def get_conv_and_pool_params_at_stage_1():\n",
    "    conv_flt_shape = ([3, 3, 1, 16])\n",
    "    conv_stride    = ([1, 2, 2, 1])\n",
    "    pool_shape     = ([1, 2, 2, 1])\n",
    "    pool_stride    = ([1, 2, 2, 1])\n",
    "    \n",
    "\n",
    "    \n",
    "    return conv_flt_shape, conv_stride, pool_shape, pool_stride\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------#---------------------------------------#\n",
    "\n",
    "def get_weight(w_name, shape, dtype):\n",
    "    \n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev = 0.2, seed = 23, dtype = tf.float32), name = w_name)\n",
    "  \n",
    "    \n",
    "    \n",
    "\n",
    "#---------------------------#---------------------------------------#\n",
    "\n",
    "def get_total_no_of_neurons(shape_of_conv_out):\n",
    "    neurons = 1\n",
    "    for num in shape_of_conv_out:\n",
    "        if num is not None:\n",
    "            neurons = neurons * num\n",
    "    return neurons\n",
    "    \n",
    "\n",
    "#---------------------------#---------------------------------------#\n",
    "\n",
    "def conv_bn_relu_stage_1(data, conv_flt_shape, stride, pool_size, pool_stride):\n",
    "    \n",
    "    conv_flt  = get_weight(\"weight1\", conv_flt_shape, tf.float32)\n",
    "    \n",
    "    data      = tf.nn.conv2d(data, conv_flt, strides = stride, padding = \"SAME\")\n",
    "    data_norm = batch_normalize(data, conv_flt_shape[-1])\n",
    "    data_relu = tf.nn.relu(data_norm)\n",
    "    data_pool = tf.nn.max_pool(data, ksize = pool_size, strides = pool_stride, padding = 'SAME')\n",
    "    \n",
    "    return data_pool\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------#---------------------------------------#\n",
    "'''\n",
    "This function is equla to one residual block in each residual layer\n",
    "'''\n",
    "def conv_bn_relu_resd_stage(data, conv_flt_shape, stride_1, stride_2, stride_3, padding_1, padding_2, padding_3,\n",
    "                                            dim_change, in_channels, num_channels, block_no):\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(\"conv_1_resd\"):\n",
    "        \n",
    "        tf.cast(conv_flt_shape, tf.int32)\n",
    "        conv_wt_1 = get_weight((\"conv_wt_1_\" + str(block_no) + \"_\"+ str(num_channels)), conv_flt_shape, tf.float32)\n",
    "        conv_1    = tf.nn.conv2d(data, conv_wt_1, strides = [1, stride_1, stride_1, 1], padding = padding_1)\n",
    "        bn_1      = batch_normalize(conv_1, conv_1.get_shape().as_list()[-1]) \n",
    "        relu_1    = tf.nn.relu(bn_1)\n",
    "    \n",
    "    with tf.variable_scope('conv_2_resd'):\n",
    "\n",
    "        conv_flt_shape_2 = [3, 3, relu_1.get_shape().as_list()[-1], num_channels]\n",
    "        conv_wt_2 = get_weight((\"conv_wt_2_\" + str(block_no) + \"_\"+ str(num_channels)), conv_flt_shape_2, tf.float32)\n",
    "        conv_2    = tf.nn.conv2d(relu_1, conv_wt_2, strides = [1, stride_2, stride_2, 1], padding = padding_2)\n",
    "        bn_2      = batch_normalize(conv_2, conv_2.get_shape().as_list()[-1])\n",
    "        \n",
    "    '''for shortcut connection between different blocks'''\n",
    "    if dim_change:\n",
    "        #shp       = dim_change_flt_shape\n",
    "        #stride    = dim_change_stride\n",
    "        shp = 1\n",
    "        \n",
    "        conv_wt   = get_weight((\"shrt_conv_wt_\" + str(block_no) + \"_\"+ str(num_channels)), [shp, shp, in_channels, num_channels], tf.float32)\n",
    "        shrtct_in = tf.nn.conv2d(data, conv_wt, strides = [1, stride_3, stride_3, 1], padding = padding_3) \n",
    "\n",
    "        return tf.nn.relu(bn_2 + shrtct_in)\n",
    "    \n",
    "    else:\n",
    "        return tf.nn.relu(bn_2 + data)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#---------------------------#---------------------------------------#    \n",
    "\n",
    "def residual_block(r_data, num_channels, use_1_by_1_conv = False, first_block = False, block_no = 0):\n",
    "    \n",
    "    '''if first_block, then we have to increase the volumne\n",
    "       if use_1_by_1_conv then we have to change the dimensions of the shortcut input to the addition after last block'''\n",
    "    \n",
    "    stride_1 = 1\n",
    "    stride_2 = 1\n",
    "    stride_3 = 1\n",
    "    padding_1 = 'SAME'\n",
    "    padding_2 = 'SAME'\n",
    "    padding_3 = 'SAME'\n",
    "    \n",
    "    dim_change = False\n",
    "    in_channels = r_data.get_shape().as_list()[-1]\n",
    "    conv_flt_shape = [3, 3, in_channels, num_channels]\n",
    "    \n",
    "    if use_1_by_1_conv:\n",
    "        stride_3 = 2\n",
    "        padding_3 = 'VALID'\n",
    "        dim_change = True\n",
    "        conv_flt_shape = [3, 3, num_channels, num_channels]\n",
    "    if first_block:\n",
    "        stride_1 = 2  \n",
    "        dim_change = True\n",
    "        conv_flt_shape = [3, 3,  in_channels, num_channels]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    output = conv_bn_relu_resd_stage(r_data, conv_flt_shape, stride_1, stride_2, stride_3, padding_1, padding_2, \n",
    "                                          padding_3, dim_change, in_channels, num_channels, block_no)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------#---------------------------------------# \n",
    "\n",
    "def fully_connected_layer(data, num_of_labels):\n",
    "    \n",
    "    data_norm = batch_normalize(data, data.get_shape().as_list()[-1])\n",
    "    \n",
    "    \n",
    "    data_shape = data_norm.get_shape().as_list()\n",
    "    total_no_of_neurons = get_total_no_of_neurons(data_shape)\n",
    "    \n",
    "    \n",
    "    fc_wt_1 = get_weight('fc_wt_1', tf.cast([total_no_of_neurons, 10], tf.int32), tf.float32)\n",
    "    fc_b_1  = get_weight('fc_b_1', [10], tf.float32)\n",
    "    data_flatten = tf.reshape(data_norm, shape = [-1, total_no_of_neurons])\n",
    "    \n",
    "    fc_layer_out    = tf.add(tf.matmul(data_flatten, fc_wt_1), fc_b_1)\n",
    "    \n",
    "    return fc_layer_out\n",
    " \n",
    "    \n",
    "    \n",
    "#---------------------------#---------------------------------------#\n",
    "\n",
    "def perfom_average_pooling(data):\n",
    "    return tf.nn.avg_pool(data, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "            \n",
    "    \n",
    "    \n",
    "#---------------------------#---------------------------------------#\n",
    "\n",
    "def form_residual_blocks_and_fc_ouput():\n",
    "    \n",
    "    result_at_every_stage = []    \n",
    "    use_1_by_1_conv = False\n",
    "    first_block     = False\n",
    "    c_flt_shape, c_stride, pool_shape, pool_stride = get_conv_and_pool_params_at_stage_1()\n",
    "    x_1 = conv_bn_relu_stage_1(x_rs, c_flt_shape, c_stride, pool_shape, pool_stride)\n",
    "    result_at_every_stage.append(x_1)\n",
    "    \n",
    "    '''\n",
    "    filter_channels(64, 128, 256, 512) correspond to no_of_filters in various residual blocks\n",
    "    no_of_blocks correspond to number of cn-bn-relu-cn-bn-relu blocks in each residual block\n",
    "    '''    \n",
    "    \n",
    "    flt_channels, resd_blocks = get_flt_channels_and_resd_blocks()\n",
    "    \n",
    "    for flt_row in range(0, np.shape(flt_channels)[0]):\n",
    "        for resd_row in range(0, np.shape(resd_blocks)[0]):\n",
    "            if flt_row == resd_row:\n",
    "                num_channels = flt_channels[flt_row]\n",
    "                num     = resd_blocks[resd_row]\n",
    "                \n",
    "                for block_no in range(0, num):\n",
    "                    \n",
    "                    with tf.variable_scope(\"block_\" + str(block_no), reuse = True): \n",
    "                        if block_no == 0:\n",
    "                            if num_channels != 16:\n",
    "                                use_1_by_1_conv = True\n",
    "                                first_block     = True\n",
    "                            \n",
    "                            result_at_every_stage.append(residual_block(result_at_every_stage[-1], num_channels,\n",
    "                                                                        use_1_by_1_conv, first_block, block_no))\n",
    "                            use_1_by_1_conv = False\n",
    "                            first_block = False\n",
    "\n",
    "                        else:\n",
    "                            result_at_every_stage.append(residual_block(result_at_every_stage[-1], num_channels, False, False, \n",
    "                                                                                   block_no))\n",
    "\n",
    "                \n",
    "    avg_pool_res = perfom_average_pooling(result_at_every_stage[-1]) \n",
    "    \n",
    "    fc_output_layer = fully_connected_layer(avg_pool_res, classes)\n",
    "    \n",
    "    return fc_output_layer\n",
    "                \n",
    "                \n",
    "                \n",
    "#---------------------------#---------------------------------------#  \n",
    "    \n",
    "    \n",
    "def ResNet_model():\n",
    "    \n",
    "    resnet_model        = form_residual_blocks_and_fc_ouput()\n",
    "    \n",
    "    cost                = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_rs, logits = resnet_model))\n",
    "    train_optim         = tf.train.AdamOptimizer(learning_rate =0.001).minimize(cost)\n",
    "    correctly_predicted = tf.equal(tf.argmax(resnet_model, 1), tf.argmax(y_rs, 1))\n",
    "    accuracy            = tf.reduce_mean(tf.cast(correctly_predicted, tf.float32))\n",
    "    \n",
    "    return resnet_model, train_optim, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "##########################################################\n",
    "def read_data(directory_path, is_train_data):\n",
    "    if is_train_data:\n",
    "        mnsit_data = pd.read_csv(directory_path, header=None, low_memory = False)\n",
    "        mnsit_data.drop(0, axis = 0, inplace = True)\n",
    "        train_Y    = mnsit_data[0].astype(np.float32)\n",
    "        mnsit_data.drop(0, axis = 1, inplace = True)\n",
    "        mnsit_data = mnsit_data.astype(np.float32)\n",
    "\n",
    "        return mnsit_data, train_Y\n",
    "    \n",
    "    else:\n",
    "        mnsit_test = pd.read_csv(directory_path, header = None, low_memory = False)\n",
    "        mnsit_test.drop(0, axis = 0, inplace = True)\n",
    "        mnsit_test = mnsit_test.astype(np.float32)\n",
    "        \n",
    "        return mnsit_test\n",
    "    \n",
    "    \n",
    "    \n",
    "##########################################################\n",
    "def split_the_train_data(train_X, train_Y):\n",
    "    train_x, train_y, test_x, test_y = train_test_split(train_X, train_Y, test_size = 0.2, \n",
    "                                                        random_state = 42)\n",
    "    \n",
    "    return [[train_x, test_x], [train_y, test_y]]\n",
    "    \n",
    "##########################################################\n",
    "def convert_labels_to_one_hot_encoding_format(train_y, test_y):\n",
    "    one_hot_encoder = OneHotEncoder(categories = 'auto')\n",
    "    train_y_encoded = one_hot_encoder.fit_transform(train_y).toarray()\n",
    "    test_y_encoded  = one_hot_encoder.fit_transform(test_y).toarray()\n",
    "    return train_y_encoded.astype(np.float32), test_y_encoded.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# def convert_input_to_image_format(row):\n",
    "#     return row.values.reshape(28, 28)\n",
    "def convert_input_to_image_format(data):\n",
    "    output = []\n",
    "    no_of_rows = np.shape(data)[0]\n",
    "    for row_num in range(0, no_of_rows):\n",
    "        output.append(data.iloc[row_num].values.reshape(28, 28, 1))\n",
    "    \n",
    "    return np.array(output).astype(np.float32)\n",
    "    \n",
    "\n",
    "\n",
    "##########################################################\n",
    "def standardize_the_data(train_data, test_data):\n",
    "    scaler = StandardScaler().fit(train_data)\n",
    "    train_data_scaled = scaler.transform(train_data)\n",
    "    test_data_scaled  = scaler.transform(test_data)\n",
    "    return pd.DataFrame(train_data_scaled, dtype = np.float32), pd.DataFrame(test_data_scaled, dtype = np.float32)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = read_data('/Users/vijay/Downloads/digit-recognizer/train.csv', True)\n",
    "test_X           = read_data('/Users/vijay/Downloads/digit-recognizer/test.csv', False)\n",
    "\n",
    "train_test_data  = split_the_train_data(train_X, train_Y)\n",
    "train_x, train_y = train_test_data[0]\n",
    "test_x, test_y   = train_test_data[1]\n",
    "\n",
    "train_x_standardized, test_x_standardized = standardize_the_data(train_x, test_x)\n",
    "# train_x_reshaped = train_x_standardized.apply(convert_input_to_image_format, axis = 1)\n",
    "\n",
    "train_x_reshaped = convert_input_to_image_format(train_x_standardized)\n",
    "test_x_reshaped   = convert_input_to_image_format(test_x_standardized)\n",
    "\n",
    "train_y_encoded, test_y_encoded = convert_labels_to_one_hot_encoding_format(train_y.values.reshape(-1, 1), \n",
    "                                                                           test_y.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "del(train_x)\n",
    "del(test_x)\n",
    "del(train_y)\n",
    "del(test_y)\n",
    "del(train_x_standardized)\n",
    "del(test_x_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ResNet_model():\n",
    "    with tf.Session() as session:\n",
    "        count = 0\n",
    "        model, optimizer, accuracy = ResNet_model()\n",
    "        \n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver(tf.trainable_variables())\n",
    "#         flt_channels = [64, 128, 256]\n",
    "#         resd_blocks = [3, 6, 4]\n",
    "        for epoch in range(0, 5):\n",
    "            count =0\n",
    "            for i in range(0, len(train_x_reshaped), batch_size):\n",
    "                if count <= 100:\n",
    "                    print('--------------- ' + str(count))\n",
    "                    train_x = train_x_reshaped[i : i + batch_size, :]\n",
    "                    train_y = train_y_encoded[i : i + batch_size, :]\n",
    "                    _, accuracy_val = session.run([optimizer, accuracy], feed_dict = {x_rs : train_x, \n",
    "                                                                                      y_rs : train_y })\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "                count = count + 1\n",
    "                \n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                print(epoch, accuracy_val)\n",
    "\n",
    "    \n",
    "        save_path = saver.save(session, \"./resnet_artist_model\")\n",
    "        \n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_fc = run_ResNet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    meta_graph = tf.train.import_meta_graph('/resnet_artist_model.meta')\n",
    "    meta_graph.restore(session, tf.train.latest_checkpoint('./'))\n",
    "    \n",
    "    prediction = session.run(resnet_fc, feed_dict = {x_rs : test_x_reshaped})\n",
    "    print((session.run(tf.nn.softmax(prediction))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
